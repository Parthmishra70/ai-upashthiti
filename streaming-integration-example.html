<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Streaming Face Recognition Integration</title>
    <style>
        body { font-family: Arial, sans-serif; max-width: 1000px; margin: 0 auto; padding: 20px; }
        .success { background: #4caf50; color: white; padding: 15px; margin-bottom: 20px; border-radius: 5px; }
        .example { background: #f5f5f5; padding: 20px; margin: 20px 0; border-radius: 8px; }
        .button { background: #2196F3; color: white; padding: 12px 24px; border: none; border-radius: 6px; cursor: pointer; margin: 5px; }
        .button:hover { background: #1976D2; }
        .results { background: #e3f2fd; padding: 15px; margin: 15px 0; border-radius: 6px; }
        .code { background: #333; color: #0f0; padding: 15px; border-radius: 6px; font-family: monospace; margin: 10px 0; overflow-x: auto; }
        .video-container { display: flex; gap: 20px; margin: 20px 0; }
        .video-box { flex: 1; }
        video { width: 100%; max-width: 300px; border: 2px solid #ddd; border-radius: 8px; }
        .face-results { min-height: 200px; background: #f9f9f9; padding: 15px; border-radius: 8px; }
    </style>
</head>
<body>
    <div class="success">
        <h2>üé• AI Upashthiti - Streaming Face Recognition</h2>
        <p><strong>Live API:</strong> https://web-production-13b09.up.railway.app</p>
        <p><strong>Streaming Endpoint:</strong> POST /api/analyze</p>
    </div>

    <h1>üåê How Other Websites Can Integrate Streaming Face Recognition</h1>

    <div class="example">
        <h3>üéØ Real-time Video Stream Integration</h3>
        <p>Other websites can send video frames to your API and get real-time face recognition results:</p>
        
        <div class="video-container">
            <div class="video-box">
                <h4>üìπ Live Camera Feed</h4>
                <video id="videoElement" autoplay muted></video>
                <br>
                <button class="button" onclick="startCamera()">üì∑ Start Camera</button>
                <button class="button" onclick="captureFrame()">üì∏ Analyze Frame</button>
            </div>
            <div class="video-box">
                <h4>üîç Recognition Results</h4>
                <div id="faceResults" class="face-results">
                    Click "Start Camera" and "Analyze Frame" to test...
                </div>
            </div>
        </div>
    </div>

    <div class="example">
        <h3>üíª JavaScript Integration Code</h3>
        <p>Here's how any website can integrate your streaming face recognition:</p>
        
        <div class="code">
// üé• Real-time Face Recognition Integration
const API_URL = 'https://web-production-13b09.up.railway.app';

class FaceRecognitionStream {
    constructor(videoElement) {
        this.video = videoElement;
        this.canvas = document.createElement('canvas');
        this.ctx = this.canvas.getContext('2d');
        this.isStreaming = false;
    }

    // Start camera and begin streaming
    async startStreaming() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ 
                video: { width: 640, height: 480 } 
            });
            this.video.srcObject = stream;
            this.isStreaming = true;
            
            // Analyze frames every 2 seconds
            this.streamInterval = setInterval(() => {
                this.analyzeCurrentFrame();
            }, 2000);
            
        } catch (error) {
            console.error('Camera access denied:', error);
        }
    }

    // Capture and analyze current video frame
    async analyzeCurrentFrame() {
        if (!this.isStreaming) return;

        // Capture frame from video
        this.canvas.width = this.video.videoWidth;
        this.canvas.height = this.video.videoHeight;
        this.ctx.drawImage(this.video, 0, 0);
        
        // Convert to blob
        this.canvas.toBlob(async (blob) => {
            await this.sendFrameToAPI(blob);
        }, 'image/jpeg', 0.8);
    }

    // Send frame to your API for analysis
    async sendFrameToAPI(imageBlob) {
        const formData = new FormData();
        formData.append('file', imageBlob, 'frame.jpg');

        try {
            const response = await fetch(`${API_URL}/api/analyze`, {
                method: 'POST',
                body: formData
            });

            if (response.ok) {
                const result = await response.json();
                this.handleRecognitionResults(result);
            }
        } catch (error) {
            console.error('API Error:', error);
        }
    }

    // Handle recognition results
    handleRecognitionResults(result) {
        console.log('üîç Recognition Results:', result);
        
        result.results.forEach(face => {
            if (face.name !== 'Unknown') {
                console.log(`‚úÖ Recognized: ${face.name} (${(face.confidence * 100).toFixed(1)}%)`);
                
                // Send to your attendance system
                this.logAttendance(face.name, face.confidence, face.datetime);
            }
        });
    }

    // Log attendance in your system
    logAttendance(name, confidence, timestamp) {
        // Send to your database/backend
        console.log(`üìù Attendance: ${name} at ${timestamp}`);
        
        // Example: Send to your backend
        fetch('/your-backend/attendance', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                student_name: name,
                confidence: confidence,
                timestamp: timestamp,
                source: 'face_recognition'
            })
        });
    }

    stopStreaming() {
        this.isStreaming = false;
        if (this.streamInterval) {
            clearInterval(this.streamInterval);
        }
    }
}

// Usage in any website:
const video = document.getElementById('myVideo');
const faceStream = new FaceRecognitionStream(video);
faceStream.startStreaming();
        </div>
    </div>

    <div class="example">
        <h3>üè´ School Website Integration Example</h3>
        <div class="code">
&lt;!-- School Website HTML --&gt;
&lt;div class="attendance-system"&gt;
    &lt;h2&gt;üìö Smart Attendance System&lt;/h2&gt;
    &lt;video id="classroomCamera" autoplay&gt;&lt;/video&gt;
    &lt;div id="attendanceList"&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
// School's attendance integration
class SchoolAttendanceSystem {
    constructor() {
        this.API_URL = 'https://web-production-13b09.up.railway.app';
        this.attendanceToday = new Set();
    }

    async startClassAttendance() {
        const video = document.getElementById('classroomCamera');
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;

        // Check attendance every 5 seconds
        setInterval(() => {
            this.checkStudentAttendance(video);
        }, 5000);
    }

    async checkStudentAttendance(video) {
        // Capture frame
        const canvas = document.createElement('canvas');
        const ctx = canvas.getContext('2d');
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        ctx.drawImage(video, 0, 0);

        canvas.toBlob(async (blob) => {
            const formData = new FormData();
            formData.append('file', blob);

            try {
                const response = await fetch(`${this.API_URL}/api/analyze`, {
                    method: 'POST',
                    body: formData
                });

                const result = await response.json();
                this.processAttendance(result);
            } catch (error) {
                console.error('Attendance check failed:', error);
            }
        });
    }

    processAttendance(result) {
        result.results.forEach(face => {
            if (face.name !== 'Unknown' && !this.attendanceToday.has(face.name)) {
                this.markPresent(face.name, face.confidence);
                this.attendanceToday.add(face.name);
            }
        });
    }

    markPresent(studentName, confidence) {
        console.log(`‚úÖ ${studentName} marked present (${(confidence * 100).toFixed(1)}%)`);
        
        // Update UI
        const attendanceList = document.getElementById('attendanceList');
        const entry = document.createElement('div');
        entry.innerHTML = `
            &lt;p&gt;‚úÖ ${studentName} - Present (${new Date().toLocaleTimeString()})&lt;/p&gt;
        `;
        attendanceList.appendChild(entry);

        // Save to school database
        this.saveToSchoolDatabase(studentName, confidence);
    }

    saveToSchoolDatabase(studentName, confidence) {
        // Send to school's backend system
        fetch('/school-api/attendance', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                student: studentName,
                timestamp: new Date().toISOString(),
                confidence: confidence,
                method: 'face_recognition'
            })
        });
    }
}

// Start the system
const attendanceSystem = new SchoolAttendanceSystem();
attendanceSystem.startClassAttendance();
&lt;/script&gt;
        </div>
    </div>

    <div class="example">
        <h3>üè¢ Office/Event Integration Example</h3>
        <div class="code">
// üè¢ Office Check-in System
class OfficeCheckInSystem {
    constructor() {
        this.API_URL = 'https://web-production-13b09.up.railway.app';
        this.checkedInToday = new Set();
    }

    async setupEntryCamera() {
        const video = document.getElementById('entryCamera');
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        video.srcObject = stream;

        // Continuous monitoring
        setInterval(() => {
            this.monitorEntry(video);
        }, 3000);
    }

    async monitorEntry(video) {
        // Capture and analyze frame
        const canvas = document.createElement('canvas');
        const ctx = canvas.getContext('2d');
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        ctx.drawImage(video, 0, 0);

        canvas.toBlob(async (blob) => {
            const formData = new FormData();
            formData.append('file', blob);

            const response = await fetch(`${this.API_URL}/api/analyze`, {
                method: 'POST',
                body: formData
            });

            const result = await response.json();
            this.handleEntry(result);
        });
    }

    handleEntry(result) {
        result.results.forEach(face => {
            if (face.name !== 'Unknown') {
                this.processEmployeeEntry(face);
            }
        });
    }

    processEmployeeEntry(face) {
        const employeeId = face.student_id || face.name;
        
        if (!this.checkedInToday.has(employeeId)) {
            this.checkInEmployee(face.name, employeeId, face.confidence);
            this.checkedInToday.add(employeeId);
            
            // Show welcome message
            this.showWelcomeMessage(face.name);
        }
    }

    checkInEmployee(name, employeeId, confidence) {
        console.log(`üè¢ ${name} checked in (ID: ${employeeId})`);
        
        // Send to HR system
        fetch('/hr-system/checkin', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                employee_name: name,
                employee_id: employeeId,
                check_in_time: new Date().toISOString(),
                confidence: confidence,
                method: 'facial_recognition'
            })
        });
    }

    showWelcomeMessage(name) {
        // Display welcome message on screen
        const welcomeDiv = document.getElementById('welcomeMessage');
        welcomeDiv.innerHTML = `
            &lt;h2&gt;Welcome, ${name}! üëã&lt;/h2&gt;
            &lt;p&gt;Check-in successful at ${new Date().toLocaleTimeString()}&lt;/p&gt;
        `;
        
        // Clear after 3 seconds
        setTimeout(() => {
            welcomeDiv.innerHTML = '';
        }, 3000);
    }
}
        </div>
    </div>

    <div class="example">
        <h3>üìä API Response Format</h3>
        <p>Your <code>/api/analyze</code> endpoint returns this data structure:</p>
        <div class="code">
{
  "results": [
    {
      "name": "Pathak",
      "confidence": 0.85,
      "student_id": "STU001",
      "image": "data:image/jpeg;base64,/9j/4AAQ...", // Masked face
      "datetime": "2025-06-29T16:45:30.123456",
      "bbox": [100, 150, 200, 250]
    }
  ],
  "total_faces": 2,
  "recognized_faces": 1,
  "message": "Processed 2 faces, recognized 1 students",
  "model_used": "buffalo_l",
  "timestamp": "2025-06-29T16:45:30.123456"
}
        </div>
    </div>

    <script>
        const API_URL = 'https://web-production-13b09.up.railway.app';
        let video, canvas, ctx;

        async function startCamera() {
            try {
                video = document.getElementById('videoElement');
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { width: 640, height: 480 } 
                });
                video.srcObject = stream;
                
                canvas = document.createElement('canvas');
                ctx = canvas.getContext('2d');
                
                document.getElementById('faceResults').innerHTML = '‚úÖ Camera started! Click "Analyze Frame" to test recognition.';
            } catch (error) {
                document.getElementById('faceResults').innerHTML = '‚ùå Camera access denied. Please allow camera access.';
            }
        }

        async function captureFrame() {
            if (!video || !video.videoWidth) {
                alert('Please start camera first');
                return;
            }

            // Capture frame
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            ctx.drawImage(video, 0, 0);

            // Convert to blob and send to API
            canvas.toBlob(async (blob) => {
                const formData = new FormData();
                formData.append('file', blob, 'frame.jpg');

                try {
                    document.getElementById('faceResults').innerHTML = '‚è≥ Analyzing frame...';
                    
                    const response = await fetch(`${API_URL}/api/analyze`, {
                        method: 'POST',
                        body: formData
                    });

                    if (response.ok) {
                        const result = await response.json();
                        displayResults(result);
                    } else {
                        throw new Error(`HTTP ${response.status}`);
                    }
                } catch (error) {
                    document.getElementById('faceResults').innerHTML = `‚ùå Error: ${error.message}`;
                }
            }, 'image/jpeg', 0.8);
        }

        function displayResults(result) {
            let html = `
                <h4>üîç Analysis Results</h4>
                <p><strong>Total Faces:</strong> ${result.total_faces}</p>
                <p><strong>Recognized:</strong> ${result.recognized_faces}</p>
                <p><strong>Message:</strong> ${result.message}</p>
                <hr>
            `;

            if (result.results.length > 0) {
                html += '<h5>üë• Detected Faces:</h5>';
                result.results.forEach((face, index) => {
                    html += `
                        <div style="border: 1px solid #ddd; padding: 10px; margin: 10px 0; border-radius: 5px;">
                            <p><strong>Name:</strong> ${face.name}</p>
                            <p><strong>Confidence:</strong> ${(face.confidence * 100).toFixed(1)}%</p>
                            <p><strong>Time:</strong> ${new Date(face.datetime).toLocaleTimeString()}</p>
                            ${face.student_id ? `<p><strong>ID:</strong> ${face.student_id}</p>` : ''}
                            <img src="${face.image}" style="max-width: 100px; border-radius: 5px;" alt="Masked face">
                        </div>
                    `;
                });
            } else {
                html += '<p>No faces detected in this frame.</p>';
            }

            document.getElementById('faceResults').innerHTML = html;
        }
    </script>
</body>
</html>